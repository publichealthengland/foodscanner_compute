{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"model.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"5AHZulflnLPY"},"source":["import os\n","\n","import pandas as pd\n","import spacy\n","from sklearn.model_selection import train_test_split\n","from spacy.gold import docs_to_json"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N7YbliXbnLPf"},"source":["# Data preparation\n","\n","- Use `dtype` for performance\n","- `ingredients` is a string of ingredients delimeted with `|`, replace with `.`. Fill empty cells with `None` as the lack of ingredients is significant\n","- `cooking_type` is a string of cooking types categories delimeted with `|`, replace with `.`. However, before replacing, fill empty cells with `None` as the lack of a cooking type is significant\n","- Some products have duplicated `description`. To remove them, we set `pvid` as the index and sort it in an ascending order, then drop rows with duplicated `description` but keeping the one with the last `pvid` (i.e. the most recent product)\n","- Drop rows with any empty cell. `ingredients` and `cooking_type` empty cells are now `None` so will not be dropped\n","- Concatenate all columns using '. ' into new column `text`"]},{"cell_type":"code","metadata":{"id":"1rHqV3jAnLPg"},"source":["df = pd.read_excel(\n","    os.path.join(\n","        'data',\n","        '200901_PHE_category_sheet.xlsx',\n","    ),\n","    usecols=[\n","        'lProductVersionID',\n","        'sDescription',\n","        'sCategoryLevel1',\n","        'sCategoryLevel2',\n","        'regulated_product_name',\n","        'ingredients',\n","        'storage_env',\n","        'pack_type',\n","        'cooking_type',\n","        'PHE_category_jan',\n","    ],\n","    dtype={\n","        'lProductVersionID': 'uint64',\n","        'sDescription': str,\n","        'sCategoryLevel1': 'category',\n","        'sCategoryLevel2': 'category',\n","        'regulated_product_name': str,\n","        'ingredients': str,\n","        'storage_env': 'category',\n","        'pack_type': 'category',\n","        'cooking_type': str,\n","        'PHE_category_jan': 'category',\n","    },\n",").rename(\n","    columns={\n","        'lProductVersionID': 'pvid',\n","        'sDescription': 'description',\n","        'sCategoryLevel1': 'category_level_1',\n","        'sCategoryLevel2': 'category_level_2',\n","        'PHE_category_jan': 'label',\n","    }\n",").assign(\n","    ingredients=lambda df: df['ingredients'].str.replace(\n","        '|', '.').fillna('None'),\n","    cooking_type=lambda df: df['cooking_type'].fillna('None').str.replace(\n","        '|', '.'),\n",").set_index(\n","    'pvid',\n",").sort_index(\n","    ascending=True,\n",").drop_duplicates(\n","    subset='description',\n","    keep='last',\n",").dropna(\n","    how='any',\n",").assign(\n","    text=lambda df: df.apply(\n","        '. '.join,\n","        axis=1,\n","    )\n",")\n","\n","df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X9SRbjb1nLPn"},"source":["#### - Get unique labels"]},{"cell_type":"code","metadata":{"id":"06slzyJhnLPo"},"source":["labels = df['label'].unique()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UVf8C1sonLPs"},"source":["#### - Concat labels for examples with multi-labels"]},{"cell_type":"code","metadata":{"id":"e1ApPrk1nLPt"},"source":["df = df.groupby('text')['label'].apply(\n","    set).reset_index().rename(\n","        columns={'label': 'multilabel'}\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_b_3sx71nLP1"},"source":["#### - Convert text and labels into a SpaCy compatible format"]},{"cell_type":"code","metadata":{"id":"vorkwLWNnLP5"},"source":["nlp = spacy.load('en_core_web_sm')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ihpRQlRnLQD"},"source":["def convert_to_spacy(s, labels):\n","    \"\"\"\n","    Convert text and labels into a spaCy compitable format\n","    \"\"\"\n","    cats = {\n","        label:\n","        1.0 if label in s['multilabel']\n","        else 0.0\n","        for label in labels\n","    }\n","\n","    # make spacy document from the 'text' column\n","    # Update document categories to cats dictionary\n","    doc = nlp(s['text'])\n","    doc.cats = cats\n","\n","    return docs_to_json([doc])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MQHQAc4LnLQK"},"source":["df['spacy'] = df.apply(\n","    lambda s: convert_to_spacy(s, labels),\n","    axis=1,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dpkyIqBNnLQR"},"source":["#### - Split data 70/30 for train/val and save results into json files"]},{"cell_type":"code","metadata":{"id":"3--ClLOZnLQR"},"source":["def split_save_json(df, test_size):\n","    \"\"\"\n","    Split data 30/70 and stratify by label\n","    Save into json\n","    \"\"\"\n","    train, val = train_test_split(\n","        df['spacy'],\n","        test_size=test_size,\n","        random_state=42,\n","        shuffle=True,\n","    )\n","\n","    train.to_json(\n","        os.path.join(\n","            'data',\n","            'dataset_spacy_train.json',\n","        ),\n","        orient='records',\n","    )\n","\n","    val.to_json(\n","        os.path.join(\n","            'data',\n","            'dataset_spacy_val.json',\n","        ),\n","        orient='records',\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DzmnlsBOnLQW"},"source":["split_save_json(df, test_size=0.3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8izADo6SnLQZ"},"source":["# Training and Validation\n","\n","- AUC ROC score:\n","    - Training: $100\\%$\n","    - Testing: $97\\%$\n","    \n","#### - Run in CLI\n","\n","`python -m spacy train en training data/dataset_spacy_train.json data/dataset_spacy_val.json --base-model en_core_web_md --pipeline textcat --n-iter 30 --n-early-stopping 3 --version 1.0`"]},{"cell_type":"markdown","metadata":{"id":"tmYjYPrbnLQa"},"source":["# Predict"]},{"cell_type":"markdown","metadata":{"id":"Mf5OhM89nLQa"},"source":["### Read example JSON file\n","\n","- Parse out all the features\n","    - `category_level_1`: string category\n","    - `category_level_2`: string category\n","    - `regulated_product_name`: string\n","    - `ingredients`: list of strings. Join with '. '\n","    - `storage_env`: string category\n","    - `pack_type`: string category\n","    - `cooking_type`: a list of categories that only exists if there are cooking types. If it does exist, concatenate items with '. ', otherwise, return 'None'\n","    - `text`: concatenated from all above features"]},{"cell_type":"code","metadata":{"id":"qXGDK_nNnLQb"},"source":["df = pd.read_json(\n","    os.path.join(\n","        'data',\n","        'trial-json-products.json',\n","    ),\n","    orient='records',\n","    encoding='utf-16',\n","    lines=False,\n",").set_index(\n","    'pvid',\n",").sort_index(\n","    ascending=True,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i5cAtxbhnLQf"},"source":["df['category_level_1'] = df['categories'].apply(\n","    lambda\n","    c: c[0]['description'],\n",")\n","\n","df['category_level_2'] = df['categories'].apply(\n","    lambda\n","    c: c[1]['description'],\n",")\n","\n","df['regulated_product_name'] = df['languages'].apply(\n","    lambda\n","    c: c[0]['groupingSets'][0]['attributes']['regulatedProductName']\n",")\n","\n","df['ingredients'] = df['languages'].apply(\n","    lambda\n","    c: '.'.join(\n","        c[0]['groupingSets'][0]['attributes']['ingredients']\n","    )\n",")\n","\n","df['storage_env'] = df['languages'].apply(\n","    lambda\n","    c: c[0]['groupingSets'][0]['attributes']['storageType'][0]\n","    ['lookupValue']\n",")\n","\n","df['pack_type'] = df['languages'].apply(\n","    lambda\n","    c: c[0]['groupingSets'][0]['attributes']['packType'][0]\n","    ['lookupValue']\n",")\n","\n","\n","def parse_cooking_guidelines(c):\n","    try:\n","        guidelines = [\n","            item['nameValue']\n","            for item in c[0]['groupingSets'][0]['attributes']\n","            ['cookingGuidelines']\n","        ]\n","        return '. '.join(set(guidelines))\n","\n","    except KeyError:\n","        return 'None'\n","\n","\n","df['cooking_type'] = df['languages'].apply(\n","    parse_cooking_guidelines\n",")\n","\n","df = df[[\n","    'category_level_1',\n","    'category_level_2',\n","    'regulated_product_name',\n","    'ingredients',\n","    'storage_env',\n","    'pack_type',\n","    'cooking_type',\n","]]\n","\n","df['text'] = df.apply(\n","    lambda s: '. '.join(s[s.notna()]),\n","    axis=1,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vZhkwNA0nLQi"},"source":["#### - Load best trained model"]},{"cell_type":"code","metadata":{"id":"mgq8re2NnLQj"},"source":["nlp = spacy.load(\n","    os.path.join(\n","        'training',\n","        'model-best',\n","    )\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aI4G-w0UnLQn"},"source":["#### - Get the category with the highest score"]},{"cell_type":"code","metadata":{"id":"OlY5fI2WnLQo"},"source":["def predict(text):\n","    doc = nlp(text)\n","    return max(\n","        doc.cats,\n","        key=lambda key: doc.cats[key],\n","    )\n","\n","\n","df['predict'] = df['text'].apply(predict)"],"execution_count":null,"outputs":[]}]}